---
title: "Лекция: Метод главных компонент"
author: "Георгий Мороз, Ольга Ляшевская, Илья Щуров, НИУ ВШЭ"
date: "5 марта 2016"
output: html_document

---


```{r setup, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
library(knitr)
library(rgl)
knit_hooks$set(webgl = hook_webgl)
Sys.setlocale('LC_ALL',"ru_RU.UTF-8")
set.seed(124)
```

```{r, echo=F}
# Лекция: Метод главных компонент

# *Георгий Мороз, Ольга Ляшевская, Илья Щуров*
```

Курс «Анализ лингвистических данных: квантитативные методы и визуализация».

Школа лингвистики НИУ ВШЭ, магистерская программа «Теория языка и компьютерная лингвистика», 2015-16 учебный год.

[Школа лингвистики](http://ling.hse.ru/) | [Все материалы курса](http://hsequantling.wikispaces.com/) | [Исходные коды на Github](https://github.com/ischurov/hsequantling)

<span style='font-size:80%'>Данный материал доступен под лицензией [CC BY-SA
4.0](https://creativecommons.org/licenses/by-sa/4.0/). При использовании обязательно упоминание авторов курса и аффилиации. При наличии технической возможности необходимо также указать активную гиперссылку на [страницу курса](http://hsequantling.wikispaces.com/).<span>

---

## Постановка задачи

> Словарь Вильяма Шекспира, по подсчёту исследователей, составляет 12000 слов. Словарь негра из людоедского племени «Мумбо-Юмбо» составляет 300 слов. Эллочка Щукина легко и свободно обходилась тридцатью.<br/>
> *И. Илья и Е. Петров. Двенадцать стульев*


С данными бывают две проблемы: либо их слишком мало, либо их слишком много. Сегодня мы поговорим о второй проблеме.

Есть такая область исследования — определение авторства текстов. Допустим, у нас есть массив текстов, автор которых неизвестен. Может быть эти тексты принадлежат одному и тому же человеку, может быть разным. Может быть мы догадываемся о том, кто является автором, а может быть и нет. Если бы эти тексты были написаны ручкой на бумаге, мы могли бы ответить на какие-то вопросы об авторстве, сравнивая почерки. Но сейчас перед нами чаще «голый» текст, не содержащий таких естественных индивидуальных признаков, как почерк. 

Тем не менее, разумно предположить, что эти признаки всё-таки есть. Одни люди пишут длинными предложениями, другие короткими. Одни используют много разных слов, другие ограничиваются небольшим запасом. Одни используют много глаголов, другие мало. У каждого автора есть свой стиль и этот стиль можно извлечь из текста. Как это сделать?

Для каждого текста можно вычислить огромное количество параметров. Среднюю длину предложения. Разброс длин предложений. Распределение слов. Продуктивность аффиксов. Процент существительных, прилагательных, глаголов. И ещё кучу всего. В общем, можно превратить каждый текст в длинный-длинный вектор. Взяв много текстов, можно записать их параметры в широкую табличку.

Но дальше возникает проблема: что, собственно говоря, делать с этим массивом данных? Как его обрабатывать? Как находить связи между разными параметрами? Как их визуализировать? 

Если у нас есть один параметр, можно нарисовать для него гистограмму. Если параметра два, можно нарисовать scatter plot, показывающий, как они связаны между собой. С большим количеством параметров так сделать нельзя: пространство, в котором можно было бы нарисовать соответствующие картинки, имеет высокую размерность и не помещается на двумерной бумаге или экране.

Что же делать? Есть разные подходы. Например, можно было бы выкинуть часть параметров, оставив лишь самые важные — но зачастую сходу непонятно, какие же из них являются более важными, а какие менее важными; что можно выкинуть, не потеряв существенной информации, а что нельзя.

Оказывается, есть математический инструмент, который позволяет уменьшать размерность пространства, в котором живут данные, теряя при этом минимум информации. Этот инструмент — метод главных компонент.

## Школьные оценки

### Одно число вместо двух
Прежде, чем обсуждать общую конструкцию, рассмотрим простой (и искусственный) пример.

У нас есть табличка с результатами теста для школьников по двум предметам — например, по русскому языку и математике.

```{r, echo = F}
library(knitr)
ave = rnorm(250, 50, 10)
incline = rnorm(250, 0, 5)
rus = ave + incline
math = ave - incline
gradebook <- data.frame(rus, math)
gradebook[1:5, ]
```

Можно нарисовать вот такую картинку:

```{r, echo=FALSE, fig.width=5, fig.height=5, fig.align='center'}
library(ggplot2)
library(grid)
library(ellipse)
theme_set(theme_gray(base_size = 18))
pointcolor <- "#D55E00"
ell <- as.data.frame(ellipse(var(gradebook), centre = sapply(gradebook, mean), npoints=1000))
basicplot = ggplot(gradebook)+
  geom_point(aes(rus,math), colour=pointcolor)+
  geom_path(data=ell, aes(x=rus, y=math), linetype=2)

basicplot + ggtitle('Рис. 1')

```
\
Точки распределены примерно внутри наклонённого вытянутого эллипса (так обычно устроено многомерное нормальное распределение). Мы видим, что оценки по этим двум предметам скоррелированы — среди школьников, получающих высокие баллы по математике, много тех, кто также получает высокие баллые по русскому языку, и наоборот. Тем не менее, есть и исключения. 

Это наши исходные данные. Теперь предположим, что нам надо уменьшить размерность — вместо двух чисел на каждого школьника хранить только одно число. Например, мы выбираем, что записать в аттестат, и по закону это должно быть только одно число, а не два. И мы хотим в этом единственном числе закодировать как можно больше информации о школьнике. Как в этом случае поступить?

Можно просто отбросить одну из переменных и оставить другую. Например, можно записывать в аттестат только оценку по русскому языку, а оценку по математике игнорировать.

С одной стороны, это не такая уж и плохая стратегия. Как мы обсуждали выше, оценки скоррелированы, и человек, сдавший русский на высокий балл, скорее всего не имеет проблем и с математикой, и наоборот.

```{r, echo=FALSE}
x0 = 50
ell_strip = ell[ell$rus > x0-1 & ell$rus<x0+1, ]
smin = min(ell_strip$math)
smax = max(ell_strip$math)
```
С другой стороны, какая-то информация всё-таки теряется. Представьте себе, что мы знаем о школьнике только тот факт, что он сдал русский на 50 баллов. Что это говорит о его математических способностях? Если посмотреть на картинку, то мы увидим, что он может находиться в любой точке из синего отрезка — его оценка по математике в этом случае колеблется примерно между `r round(smin)` и `r round(smax)` — разброс очень большой.

```{r, echo=F, fig.width=5, fig.height=5, fig.align='center', fig.retina=T}
stripcolor = "#0072B2"
basicplot +
  geom_vline(xintercept=50, linetype=1)+
  geom_segment(aes(x=x0, y=smin, xend=x0, yend=smax), size=2, colour=stripcolor, alpha=0.01)+
  geom_hline(yintercept=smin, linetype=3)+
  geom_hline(yintercept=smax, linetype=3)+
  ggtitle('Рис. 2')+
  scale_y_continuous(breaks=c(seq(0,100, by=20),round(c(smin, smax))))
  
```

Конечно, понятно, что заменяя два числа одним мы потеряем какую-то информацию, но хотелось бы всё-таки эти потери минимизировать. Можем ли мы сделать что-то лучше, чем сообщать только одну оценку из двух? Оказывается, можем.

Мы можем сконструировать новое число из двух имеющихся!

Давайте рассмотрим самый простой вариант: впишем в аттестат сумму оценок за русский язык и математику. Иными словами, мы введём новую переменную — обозначим её через $PC_1$ (почему так — будет ясно позднее), которая связана с нашими старыми переменными таким образом:

$$
PC_1=rus+math
$$

Посмотрим, насколько этот метод лучше. Пусть мы знаем, что для некоторого школьника $PC_1=100$. Что тогда можно сказать про его оценки?

Проведём на графике прямую, соответствующую условию $PC_1=100$, то есть $rus+math=100$. Она пройдёт из левого верхнего угла в правый нижний и пересечёт наш эллипсоид по некоторому отрезку.


```{r, echo=FALSE, fig.width=5, fig.height=5, fig.align='center'}
value = 100
ell_strip = ell[ell$rus+ell$math > value-0.5 & ell$rus+ell$math<value+0.5, ]
mathmin = min(ell_strip$math)
mathmax = max(ell_strip$math)

rusmin=value-mathmin
rusmax=value-mathmax

basicplot +
  ggtitle('Рис. 3')+
  stat_function(fun=function(x){100-x})+
  geom_segment(aes(x=rusmin, y=mathmin, xend=rusmax, yend=mathmax), size=2, alpha=0.01, colour=stripcolor)

```

Как и в прошлый раз, наш школьник может оказаться в любой точке этого отрезка: на этот раз мы не знаем наверняка ни оценку по математике (она колеблется где-то между `r round(mathmin)` и `r round(mathmax)`), ни оценку по русскому языку (она между `r round(rusmax)` и `r round(rusmin)`).

Тем не менее, если измерять степень нашего незнания длиной того самого отрезка, на котором может оказаться школьник, то мы видим, что она уменьшилась: новый отрезок короче старого, потому что сейчас мы пересекаем эллипсоид «поперек», а раньше пересекали «наискосок». Поэтому сообщать наше число $PC_1$ лучше, чем сообщать только одну из оценок (если, конечно, мы не знаем заранее, что получателю этой информации какая-то из двух оценок важнее другой).

### Новая система координат

Метод главных компонент — это история про введение новой, более экономной системы координат, в которой описывать наши данные проще. Вот как эта система координат будет устроена в нашем примере с оценками.

В качестве первой координаты точки мы возмём $PC_1$, то есть сумму её старых координат, а в качестве второй координаты (обозначим её через $PC_2$) возьмём *разность* её старых координат:

$$
PC_2=math-rus
$$

Например, школьник, у которого оценки по русскому и математике совпадают, имеет $PC_2$ равное нулю. Школьник со старыми координатами $math=60$ и $rus=40$ имеет новые координаты $PC_1=100$ и $PC_2=20$ и т.д. Зная старые координаты, можно найти новые, а зная новые можно найти старые — для этого нужно решить соответствующую систему уравнений.

Координата $PC_2$ имеет простую интерпретацию: это «уклон»: даже если два школьника в целом учатся одинаково хорошо, кто-то из них может быть чуть лучше другого по математике, но хуже по русскому. Можно сказать, что $PC_2$ измеряет «склонность к математике».

Что означает новая система координат геометрически? Раньше, чтобы узнать координату какой-нибудь точки, мы опускали из этой точки перпендикуляры на горизонтальную и вертикальные оси и получали таким образом её абсциссу и ординату. В новых координатах будет всё то же самое, только оси будут другие.

```{r, echo=FALSE, warning=FALSE, fig.width=5, fig.height=5, fig.align='center'}
fig4 <- basicplot +
  ggtitle('Рис. 4')+
  scale_y_continuous(limits=c(20,80))+
  scale_x_continuous(limits=c(20,80))+
  annotate("segment", x=20,y=20,xend=80,yend=80,arrow=arrow()) +
  annotate("segment", x=80,y=20,xend=20,yend=80,arrow=arrow()) +
  annotate("text", x=74, y=80, label="PC1", size=8) +
  annotate("text", x=26, y=80, label="PC2", size=8) +
  annotate("segment", x=60, y=70, xend=65, yend=65) +
  annotate("segment", x=60, y=70, xend=60-15, yend=70-15) +
  annotate("point", x=60, y=70, size=3)
  

fig4
```
\
Новые оси изображены на рисунке 4. Для того, чтобы их можно было изобразить на этом рисунке, мы отказались от «школьного» требования о том, что оси пересекаются в точке $(0, 0)$. Однако, как и раньше, эти оси перпендикулярны друг другу.

Проверьте, что множество точек, в которых $PC_1$ равно какой-нибудь константе (например, 120) является прямой, параллельной оси $PC_2$, и наоборот, множество точек, в которых $PC_2$ равно константе (например, 10) является прямой, параллельной оси $PC_1$.

Таким образом получается новая система координат. Если мы развернём картинку таким образом, чтобы $PC_1$ стала горизонтальной осью, а $PC_2$ вертикальной, то наш эллипс «ляжет на бок», а старые координаты $math$ и $rus$ будут диагональными прямыми. Получится картинка, изображённая на рис. 5.

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.width=5, fig.height=5, fig.align='center'}
attach(gradebook)
newgrades = data.frame(PC1=math+rus, PC2=math-rus)
detach(gradebook)

ell <- as.data.frame(ellipse(var(newgrades), centre = sapply(newgrades, mean), npoints=1000))
newbasic = ggplot(newgrades)+
  geom_point(aes(PC1,PC2), colour=pointcolor)+
  geom_path(data=ell, aes(x=PC1, y=PC2), linetype=2)+
  scale_x_continuous(limits=c(40,160)) +
  scale_y_continuous(limits=c(-60,60)) +
  annotate("segment",x=40,y=-60,xend=160,yend=60,arrow=arrow()) +
  annotate("segment",x=40,y=60,xend=160,yend=-60,arrow=arrow()) +
  annotate("text", x=145, y=60, label="math", size=8) +
  annotate("text", x=150, y=-60, label="rus", size=8) +
  ggtitle("Рис. 5")

newbasic
```

Заметим, что на новой картинке $PC_1$ и $PC_2$ имеют нулевую корреляцию: раньше мы знали, что школьник, хорошо успевающий по русскому, скорее всего имеет неплохую оценку и по математике, а сейчас знание $PC_1$ ничего не говорит нам о том, велик или мал $PC_2$. Геометрически это соответствует тому, что эллипсоид теперь не имеет никакого ярко выраженного наклона (вспомните лекцию про корреляцию). Это важный момент: благодаря вводу новой системы координат мы избавились от зависимостей между переменными. Именно благодаря этому новая система координат «экономнее» старой и мы можем выделить в ней переменную $PC_1$, содержащую большую часть информации.

Координата $PC_1$ называется *первой главной компонентой*, а $PC_2$ — *второй*. Заметим, что «главных компонент» получилось столько же, сколько изначально было переменных, но зато теперь мы знаем, что $PC_1$ «главнее» (содержит больше информации), чем $PC_2$.

Мы выбирали координату $PC_1$ таким образом, чтобы уменьшить длину отрезка, по которому наш эллипсоид пересекается с прямой $PC_1=const$, перпендикулярной оси. Можно действовать другим способом, который приведёт к такому же результату: подбирать направление оси $PC_1$ так, чтобы вдоль него был максимальный разброс значений. Иными словами, ось нужно направить вдоль длинной оси эллипса — тогда перпендикулярная ось пойдёт вдоль его короткой оси (с минимумом разброса). Мы будем использовать этот подход в следующем разделе.

### Связь старых переменных с новыми

На рис. 5 также видно, как связаны старые и новые переменные. Например, видно, что в $PC_1$ обе старые переменные ($rus$ и $math$) вносят положительный вклад: если увеличиваются они, то увеличивается и $PC_1$. А в $PC_2$ положительный вклад вносит математика (у неё стрелочка смотрит «вверх»), а $rus$ вносит отрицательный вклад (стрелочка направлена «вниз»). Это значит, что $PC_2$ растёт с увеличением $math$ и уменьшается с увеличением $rus$.

В нашем случае обе старые переменные вносят одинаковый вклад в $PC_1$, но эта ситуация могла бы быть и иной. Рассмотрим, например, другой датафрейм с оценками; его scatter plot изображён на рис. 6.


```{r, echo=FALSE, fig.width=5, fig.height=5, fig.align='center'}
rus = rnorm(250, 50, 10)
math = 35+0.3*rus + rnorm(250, 0, 4)
gradebook <- data.frame(rus, math)

pointcolor <- "#D55E00"
ell <- as.data.frame(ellipse(var(gradebook), centre = sapply(gradebook, mean), npoints=1000))
basicplot = ggplot(gradebook)+
  geom_point(aes(rus,math), colour=pointcolor)+
  geom_path(data=ell, aes(x=rus, y=math), linetype=2)+
  scale_x_continuous(limits=c(17, 82))+
  scale_y_continuous(limits=c(17, 82))
  

basicplot + ggtitle('Рис. 6')
```

Здесь эллипсоид повёрнут не на 45 градусов, а на меньший угол — его длинная ось лишь немножко отклоняется от горизонтали. Если бы мы ввели такие же координаты $PC_1$ и $PC_2$, как и раньше, они бы не были оптимальными. Раньше координаты $rus$ и $math$ были равноправными, а теперь они явно неравноправны: оценка по русскому содержит больше информации о школьнике, чем оценка по математике. Это связано с тем фактом, что разброс оценок по математике в этом случае гораздо меньше разброса оценок по горизонтали. Мы хотим выбрать ось $PC_1$ таким образом, чтобы разброс значений по этой оси был максимально возможным (чтобы она содержала максимум информации), то есть вдоль длинной оси эллипса (см. конец предыдущего параграфа).

Чтобы найти, как следует направить оси (или, что то же самое, как выразить $PC_1$ и $PC_2$ через старые переменные $rus$ и $math$), можно использовать функции `prcomp` или `princomp` или какие-нибудь другие (существует несколько пакетов, реализующих метод главных компонент в R):

```{r}
pca <- prcomp(gradebook)
rot <- pca$rotation
pca
```
```{r, echo=FALSE}
a11 = rot['rus', 'PC1']
a12 = rot['math', 'PC1']
a21 = rot['rus', 'PC2']
a22 = rot['math', 'PC2']
```

Матрица `Rotation` как раз и показывает, как новые оси повёрнуты относительно старых. Фактически, здесь написано:

$$
PC_1=`r a11`\times rus + `r a12`\times math
$$
$$
PC_2=`r a21`\times rus + `r a22`\times math
$$

Нарисуем оси на картинке.

```{r, echo=FALSE, fig.width=5, fig.height=5, fig.align='center'}
axis <- function(basic, v1, v2, length, title) {
  basic + annotate("segment", x=crus-length*v1, y=cmath-length*v2, xend=crus + length*v1, yend=cmath + length*v2, arrow=arrow()) + annotate("text", x=crus+length*v1, y=cmath + length*v2+2, label = title, size=6)
}

crus <- mean(gradebook$rus)
cmath <- mean(gradebook$math)
length <- 30

plot_with_axis <- axis(basicplot, a11, a12, length, "PC1")
plot_with_axis <- axis(plot_with_axis, a21, a22, length, "PC2")
plot_with_axis + ggtitle('Рис. 6')
```

Теперь переменная $rus$ вносит гораздо больший вклад в первую главную компоненту, чем переменная $math$: это видно и по картинке (ось $PC1$ почти параллельна оси $rus$), и по числам (коэффициент при $rus$ гораздо больше коэффициента при $math$).

Нарисуем теперь картинку в новых координатах. 

```{r, echo=FALSE, warning=FALSE, fig.width=5, fig.height=5, fig.align='center'}
# FROM: http://stackoverflow.com/a/6579572/3025981

PCbiplot <- function(PC, x="PC1", y="PC2") {
    # PC being a prcomp object
    data <- data.frame(obsnames=1:length(PC$x), PC$x)
    
    ell <- as.data.frame(ellipse(var(PC$x), npoints=1000))
    
    plot <- ggplot(data, aes_string(x=x, y=y)) + geom_point(color=pointcolor)
    plot <- plot + geom_hline(aes(0), yintercept=0, size=.2) + geom_vline(aes(0), xintercept=0, size=.2)
    datapc <- data.frame(varnames=rownames(PC$rotation), PC$rotation)
    mult <- min(
        (max(data[,y]) - min(data[,y])/(max(datapc[,y])-min(datapc[,y]))),
        (max(data[,x]) - min(data[,x])/(max(datapc[,x])-min(datapc[,x])))
        )
    datapc <- transform(datapc,
            v1 = 1.2 * mult * (get(x)),
            v2 = 1.2 * mult * (get(y))
            )
    plot <- plot + coord_equal() + geom_text(data=datapc, aes(x=v1, y=v2, label=varnames), size = 5, vjust=1.5, hjust=-0.2, color="black", size=4)
    plot <- plot + geom_segment(data=datapc, aes(x=0, y=0, xend=v1, yend=v2), arrow=arrow(), alpha=0.75, color="black") + scale_y_continuous(limits = c(-30,30)) + geom_path(data=ell, aes(x=PC1, y=PC2), linetype=2)
    plot
}
# END FROM
pca <- prcomp(gradebook)
PCbiplot(pca) + ggtitle("Рис. 7")
```

## Трёхмерный пример
В примере, который мы рассматривали до сих пор, было всего две переменные. Обычно метод главных компонент применяется в том случае, когда переменных больше, чем две. Чтобы понять, как он работает, мы рассмотрим самый простой случай: когда исходных переменных три.

Начнём снова с искусственных данных. Пусть наш датафрейм теперь имеет вот такой вид.
```{r, echo=F, warning=FALSE, message=FALSE}
library(pracma)

N <- 100
x <- rnorm(N)
y <- rnorm(N)
z <- rnorm(N)


C <- t(matrix(c(4, 0, 0, 0, 2, 0, 0, 0, 1), nrow = 3))

theta <- pi/4
phi <- pi/6
psi <- pi/3

rot_z <- t(matrix(c(sin(theta), cos(theta), 0,
                   cos(theta), -sin(theta), 0,
                   0, 0, 1), nrow=3))

rot_x <- t(matrix(c(1, 0, 0,
                   0, sin(phi), cos(phi),
                   0, cos(phi), -sin(phi)),nrow=3))

rot_y <- t(matrix(c(sin(psi), 0, cos(psi),
                   0,        1, 0,
                   cos(psi), 0, -sin(psi)),nrow=3))

rot = rot_y %*% rot_z %*% rot_x

C <- rot %*% C

points <- setNames(data.frame(t(C %*% as.matrix(rbind(x, y, z)))), c('x', 'y', 'z'))
print(points[1:5,])
```
В каждой строке записаны три числа. Нарисуем трёхмерный scatter plot.

```{r, echo=F, warning=FALSE, message=FALSE, webgl=T}
library(rgl)

#FROM: http://www.sthda.com/english/wiki/a-complete-guide-to-3d-visualization-device-system-in-r-r-software-and-data-visualization#add-axis-lines-and-labels

# x, y, z : numeric vectors corresponding to
#  the coordinates of points
# axis.col : axis colors
# xlab, ylab, zlab: axis labels
# show.plane : add axis planes
# show.bbox : add the bounding box decoration
# bbox.col: the bounding box colors. The first color is the
# the background color; the second color is the color of tick marks
rgl_add_axes <- function(x, y, z, axis.col = "grey",
                xlab = "x", ylab="y", zlab="z", show.plane = FALSE, 
                show.bbox = FALSE, bbox.col = c("#333377","black"))
  { 
  
  lim <- function(x){c(-max(abs(x)), max(abs(x))) * 1.1}
  # Add axes
  xlim <- lim(x); ylim <- lim(y); zlim <- lim(z)
  rgl.lines(xlim, c(0, 0), c(0, 0), color = axis.col)
  rgl.lines(c(0, 0), ylim, c(0, 0), color = axis.col)
  rgl.lines(c(0, 0), c(0, 0), zlim, color = axis.col)
  
   # Add a point at the end of each axes to specify the direction
   axes <- rbind(c(xlim[2], 0, 0), c(0, ylim[2], 0), 
                 c(0, 0, zlim[2]))
   rgl.points(axes, color = axis.col, size = 3)
  
  # Add axis labels
  rgl.texts(axes, text = c(xlab, ylab, zlab), color = "black",
             adj = c(0.5, -0.8), size = 2)
  
  # Add plane
  if(show.plane) {
    xlim <- xlim/1.1; zlim <- zlim /1.1
    rgl.quads( x = rep(xlim, each = 2), y = c(0, 0, 0, 0),
             z = c(zlim[1], zlim[2], zlim[2], zlim[1]))
  }
  
  # Add bounding box decoration
  if(show.bbox){
    rgl.bbox(color=c(bbox.col[1],bbox.col[2]), alpha = 0.5, 
          emission=bbox.col[1], specular=bbox.col[1], shininess=5, 
          xlen = 3, ylen = 3, zlen = 3) 
  }
}
# END FROM

plot3d(points$x, points$y, points$z, aspect='iso', col=pointcolor, xlab='', ylab='', zlab='', axes=F)
spheres3d(points$x, points$y, points$z, col=pointcolor, r=0.5, alpha=1)
rgl_add_axes(points$x, points$y, points$z)
rgl.viewpoint(-15, 45)
```

По картинке видно (её можно крутить!), что точки образуют вытянутое облако. По аналогии с плоским случаем, можно нарисовать эллипсоид (трёхмерный аналог эллипса), в котором лежат почти все точки.

```{r, echo=F, message=F, warning=F, webgl=T}
Sigma <- C %*% t(C)
Mean <- c(0, 0, 0)
plot3d(ellipse3d(Sigma, centre = Mean), col = "#F0E442", alpha = 0.3, add = TRUE)
```

В качестве первой главной компоненты нужно выбрать такую координату, что соответствующая координатная ось направлена вдоль того направления, вдоль которого разброс точек самый большой -- то есть вдоль длинной оси эллипсоида.
```{r, echo=F, message=F, warning=F, webgl=T}
arrow_profile <- function(len, width=0.2, headlength=2, headwidth=0.5, steps=50) {
  #returns list of X's and Y's
  #Y=f(X)
  # the graph of Y is an arrow profile
  X <- c(-len, seq(-len, len-headlength, length.out = steps %/% 2),
         len-headlength,
         seq(len-headlength+1E-5, len, length.out = steps %/% 2))
  Y <- c(0, rep(width, length(X)-1))
  for (i in 1:length(X)) {
    if (X[i] > len-headlength) {
      Y[i] = (len - X[i])*headwidth/(headlength)
    }
  }
  list(X=X, Y=Y)
}

rotate <- function(profile, thetasteps=50) {
  # rotate profile Y = f(X) around X axes
  X <- profile$X
  R <- profile$Y
  Theta <- seq(0, 2*pi+2*pi/thetasteps, length.out = thetasteps)
  mgrd <- meshgrid(X, Theta)
  X <- mgrd$X
  R <- meshgrid(R, Theta)$X
  Theta <- mgrd$Y
  Y <- R*cos(Theta)
  Z <- R*sin(Theta)
  list(x=X, y=Y, z=Z)
}

apply_matrix <- function(C, points) {
  ar <- array(unlist(points), c(dim(points[[1]]), 3))
  out <- apply(ar, 1:2, `%*%`, x = t(C))
  list(x=out[1,,],y=out[2,,],z=out[3,,])
}

data = apply_matrix(rot,rotate(arrow_profile(14)))

persp3d(x=data$x, y=data$y, z=data$z, col = "#009E73", add=T)
```

Так мы ввели первую координату, $PC_1$. Но нужно ввести ещё две. Как и в двумерном случае, оставшиеся координатные оси должны быть перпендикулярны $PC_1$. Но теперь этого недостаточно: на плоскости есть лишь одна прямая, перпендикулярная данной и проходящая через фиксированную точку, а в пространстве такие прямые образуют целую плоскость. Чтобы понять, как провести в этой плоскости вторую и третью главные компоненты, спроектируем все наши точки на эту плоскость. Для этого посмотрим на нашу картинку в направлении только что нарисованной стрелочки (посмотрим на эту стрелочку «в торец») -- так мы и получим правильную проекцию.

```{r, echo=FALSE, message=FALSE, warning=FALSE, webgl=T}
rgl.viewpoint(theta = psi*180/pi, phi = theta*180/pi)
```

В этой проекции получается картинка, похожая на ту, которую мы уже видели в двумерном случае. Большинство точек лежит в вытянутом эллипсе (являющемся проекцией нашего эллипсоида), наклонённом к горизонтали. У этого эллипса есть две оси: большая и маленкая, причём они перпендикулярны.

Вторую главную компоненту нужно выбрать таким образом, чтобы соответствующая ей ось шла в том направлении, в котором достигается максимальный разброс точек на нашей проекции. Иными словами, вторую главную компоненту следует направить вдоль длинной оси получающегося эллипса.

Третья главная компонента должна быть перпендикулярна второй и значит должна совпадать с малой осью эллипса. Разброс вдоль третьей главной компоненты минимален.

Получается такая картинка.

```{r, echo=F, warning=F, message=FALSE, webgl=T}

swap_matrix <- matrix(c(0, 1, 0, 1, 0, 0, 0, 0, 1),
                   nrow=3,
                   byrow=T)

data <- apply_matrix(
                 rot %*% swap_matrix,
                 rotate(arrow_profile(10)))

persp3d(x=data$x, y=data$y, z=data$z, col = "#D55E00", add=T)

swap_matrix <- matrix(c(0, 0, 1, 1, 0, 0, 0, 1, 0),
                   nrow=3,
                   byrow=F)

data <- apply_matrix(
                 rot %*% swap_matrix,
                 rotate(arrow_profile(6)))

persp3d(x=data$x, y=data$y, z=data$z, col = "#CC79A7", add=T)
```

Восстановим положение камеры и посмотрим, что получилось.

```{r, echo=FALSE, message=FALSE, error=FALSE, warning=FALSE, webgl=T}
rgl.viewpoint()
```

Три получающиеся оси соответствуют трём главным компонентам: зелёная -- первой ($PC_1$), оранжевая -- второй ($PC_2$) и малиновая -- третьей ($PC_3$). Если покрутить картинку, то видно, что точки лежат очень близко к плоскости, проходящей через оси $PC_1$ и $PC_2$: их отклонение от этой плоскости (равное как раз значению $PC_3$) минимальное из всех возможных.

Это означает, что первые две главные компоненты несут основную часть информации о расположении точек. Если мы «забудем» значения $PC_3$, то есть спроецируем картинку на плоскость, образованную $PC_1$ и $PC_2$, потери в информации будут минимальны.

Посмотрим, как выглядит наша картинка в плоскости, образованной двумя первыми главными компонентами.

```{r, echo=FALSE, message=F, warning=F, webgl=T}

phi_3 = asin(rot[2,3])
theta_3 = acos(rot[3,3]/sqrt(1-rot[2,3]**2))
rgl.viewpoint(theta=theta_3 * 180 / pi, phi = phi_3 * 180 / pi)

```

### Нахождение главных компонент
Теперь, когда мы понимаем, что такое «главные компоненты», можно найти их явно. Для этого используем функцию `prcomp`

```{r}
pca <- prcomp(points)
rot <- pca$rotation
pca
```

Получающаяся матрица показывает, как связаны старые координаты $(x, y, z)$ с главными компонентами.

```{r, fig.width=5, fig.height=5}
library(ggbiplot)
ggbiplot(pca, scale=0) + ggtitle("Рис. 8")
```
\
Рис. 8 практически совпадает с последним из трёхмерных рисунков -- только он повёрнут таким образом, чтобы первая главная компонента шла горизонтально, а вторая вертикально. Стрелочками отмечены направления исходных координатных осей. Их расположение относительно новых осей показывает, какой вклад каждая из них вносит в первую и вторую главные компоненты. Эта картинка называется *biplot*: *bi* потому, что на ней одновременно изображены точки и исходные координаты.

На осях написаны проценты *объяснённой дисперсии* -- эти числа показывают, какая доля общего разброса точек приходится на каждую из новых координат. Мы выбирали их таким образом, чтобы на $PC_1$ приходился максимум разброса, на $PC_2$ максимум оставшегося разброса и т.д.

Аналогичную информация -- уже о всех главных компонентах, а не только о первых двух -- можно получить с помощью функции `summary` -- ей надо скормить результат применения функции `prcomp` к нашим данным (ранее мы записали его в переменную по имени `pca`).

```{r}
smmry <- summary(pca)
smmry
```

В первой строке указывается, сколько всего дисперсии приходится на каждую из компонент, во второй -- то же самое, только в относительных величинах (первые два числа из этой строчки мы видели выше на графике), третья строка является кумулятивной суммой от второй -- она показывает, какую часть дисперсии учитывают главные компоненты вплоть до текущей. Мы видим, что первая и вторая главные компоненты в сумме покрывают примерно `r round(smmry$importance[3,2]*100)`% дисперсии, а на третью компоненту остаётся лишь `r 100-round(smmry$importance[3,2]*100)`%.

Эти данные показывают, в какой мере наши точки действительно отклоняются от плоскости, проведенной через $PC_1$ и $PC_2$ (если дисперсия, приходящаяся на первые две главные компоненты, составляет почти 100%, то отклонение мало, а если существенно меньше 100%, то велико), и помогают принять решение о том, насколько отбрасывание старших главных компонент является правомерным.

### Нормализация данных

Метод главных компонент чувствителен к выбору единиц измерения. Вернёмся к рисунку 6: оценки по русскому языку там вносят больший вклад в первую главную компоненту, потому что у них больший разброс (по сравнению с оценками по математике). Однако, представьте себе, что было бы, если бы оценки по математике записывались в 100-бальной шкале, а по русскому -- в пятибальной. Нет никаких сомнений, что в этом случае оценки по математике имели бы больше разброс, чем оценки по русскому: в пятибальной шкале особо не разбежишься. В этом случае метод главных компонент всегда бы включал математику в первую главную компоненту с большим весом, чем русский. Однако, это вряд ли было бы разумным решением: правильнее было бы перевести все оценки в одну шкалу (например, разделив 100-бальную оценку на 20).

Ситуация особенно осложняется, когда в датафрейме присутствуют данные, измеряемые в разных единицах: представьте себе, что речь идёт о спортсменах и их результатах в разных соревнованиях. Результаты по бегу можно измерять в секундах (время преодоления дистанции), а результаты по прыжкам в высоту -- в метрах. Понятно, что эти единицы несоизмеримы. Стандартный подход здесь состоит в том, чтобы произвести нормировку: разделить все значения каждой из переменных на её стандартное отклонение. В этом случае все стандартные отклонения сравняются и никаких «перекосов» из-за разных масштабов не будет. Впрочем, нужно учитывать, что в этом случае мы потеряем какую-то информацию.

### Как работает метод главных компонент

Когда мы обсуждали, как провести оси, соответствующие главным компонентам, мы говорили что-то вроде «проведём вдоль длинной оси элипсоида». Однако на практике, конечно, у нас нет никакого эллипсоида, а есть только набор точек. Как тогда выбрать оптимальную прямую?

Оказывается, очень просто. Для этого нужно для каждой прямой посчитать сумму квадратов расстояний от всех точек до этой прямой и выбрать среди них ту, для которой эта сумма квадратов будет минимальной. Это похоже на поиск регрессионной прямой: разница состоит в том, что когда мы искали регрессионную прямую, мы считали расстояние «по вертикале», а сейчас считаем обычное расстояние от точки до прямой (вдоль направления, вертикального к прямой). Конечно, всех возможных прямых очень много, но задача отыскания самой лучшей из них оказывается довольно простой: компьютеры с ней справляются очень эффективно даже для пространств высокой размерности. Поэтому метод главных компонент пользуется заслуженной любовью и популярностью.